[Математическо очакване. Кодиране с линейно предсказване]-

-Математическо очакване: Математическото очакване, известно още като средна стойност, е основно понятие в теорията на вероятностите. 

	В процеса на преминаване през символите от входното съобщение ще натрупваме статистически данни,
	позволяващи ни да пресметнем математическото очакване на следващата буква, като на изхода ще подаваме само "грешката",
	т.е. само разликата между средната стойност и кода на символа.
	Вместо да натрупваме статистика за символите на входното съобщение, както и за честотата (или вероятността) на срещане на всеки от тях,
	ще използваме проста рекурентна връзка между старата стойност на EXстар = {x1, x2, ..., xk}, и новата EXнов = {x1, x2, ..., xk, xk+1}. 
	Статистическото определение за вероятност на случайната величина X се свързва с извършване на някои опити и наблюдения над X и се дефинира като отношението на броя на благоприятните изходи към общия брой опити. 
	Да разгледаме случайна величина, 
	която приема стойности 0 или 1 в зависимост от това дали се пада лице или герб при хвърляне на монета. 
	Да предположим, че сме подхвърлили монетата във въздуха 10000 пъти, при което 5037 пъти се е паднал герб.
 	В такъв случай вероятността тази случайна величина да приеме стойност 1, 
	т. е. да се падне герб, е 5037/10000 = 0,5037.
	

	ИЗВОД-Каква все пак е ползата от алгоритъма? На пръв поглед той не води до съкращаване на размера на съобщението. Полза обаче има. 
	От една страна, той води до намаляване на амплитудата на изменение на кодираните стойности, като ги приближава до нулата от двете ѝ страни. 
	Това означава по-малки по абсолютна стойност числа (и по-малко като разнообразие от различни стойности), 
	а оттук — и по-малко необходими двоични битове за запазването им: старшите битове просто могат да се отхвърлят.

------------------------------------------------------------------------------------------------------------------------------------------
[Статистически методи]-

Алгоритъм на Шенън-Фано:
	Алгоритъмът притежава следните характерни свойства: 
	-Дължината на кодовете е променлива.
	-Буквите с по-голяма вероятност се кодират с по-малко битове от тези с по-малка вероятност. 
	-Съобщението се декодира еднозначно. 
	
	Алгоритъм:
	-Сортираме символите по вероятност на срещане в намаляващ ред. 
 	-Разделяме множеството от символите на две подмножества с (почти) равни вероятности.
	-На едното подмножество съпоставяме 0, а на другото — 1 като поредна буква.
	-Ако някое от подмножествата съдържа повече от един елемент, прилагаме за него същия процес, започвайки от стъпка 2.
	 

	Декодирането в този случай се извършва чрез разбиване на кодираното съобщение на подпоследователности (поддуми) с дължина, 
	равна на дължината на кода, след което се извършва просто заместване на всяка поддума с първообраза ѝ съгласно таблицата на кодиране. 
	В случай, че някоя от поддумите няма първообраз, декодирането е невъзможно, а в останалите случаи винаги се гарантира еднозначност. 
	Пример за равномерен код е ASCII  

 Алгоритъм на Хъфман:
------------------------------------------------------------------------------------------------------------------------------------------------------
	void huffman(void) 
	{ /* Докато гората съдържа повече от едно дърво */  
	while (forest_съдържа_поне_2_дървета) 
	{
     	findMins(i,j);       /* 1. Намиране на двата най-редки върха */     
	forest[i] = createNew(forest[i],forest[j]);/* 2. Обединяване */     
	free(forest[j]);            /* 3. Премахване на j-тото дърво */   } 
-------------------------------------------------------------------------------------------------------------------------------------------------------	  
	-Образуваме от всеки символ тривиално дърво, в корена (единствения връх) на което записваме вероятността на срещане на съответния символ.  
	-Намираме двата върха с най-малки вероятности и ги обединяваме в ново дърво с корен, съдържащ сумата от вероятностите им.  
 	-Ако има поне две дървета, преход към 2.

[Аритметично кодиране]-
-----------------------------------------------------------------------------------
	l = 0.0; 
	r = 1.0; 
	while (getSymbol(ch)) {  
	 	range = r - l;   
		l = l + range * low_range(ch);	
		 r = l + range * high_range(ch); 
	} 
	output(l);
-----------------------------------------------------------------------------------
	-Подобно на Хъфмановото кодиране,то също се основава на статистически наблюдения за честотата на срещане на всеки от символите във входното съобщение,
	но може да постигне значително по-добри резултати, тъй като изобщо се отказва от побуквеното кодиране.
	Вместо това на цялото входно съобщение се съпоставя едно-единствено дробно число между 0 и 1 с необходимата точност.

	Процесът на декодиране също изисква някои модификации. Така например, границите следва да се изменят по същия начин, както при кодирането, 
	с аналогични тестове за недостатъчна точност и др. Входното съобщение трябва да се чете на части. 
	Най-добре е за целта да се използва подходящо буфериране.
	
	Извод!
	-При кодирането по Хъфман  не се отчита достатъчно прецизно вероятността за поява на всяка от буквите.
	-Скромна ефективност заради неподходящия избор на азбука.
	!Аритметичното кодиране решава този проблем!