Задача 10.124. Варианти на кодиране по Хъфман

Нека за всяка буква в дадена азбука да имаме съпоставена вероятност за нейното срещане в стандартен текст (именно тази информация ще ни е предоставена според модела, по който работим). При кодирането на Хъфман се построява бинарно дърво по следния принцип:

Всяка буква започва със свое собствено дърво от единствен елемент;
Двете букви с най-малка вероятност за срещане се комбинират в общо дърво;
Предишната точка се повтаря докато не се получи едно голямо дърво, което обхвяща всички букви.
Ще демонстрираме алгоритъма с пример. Нека е дадена азбуката с десет букви ABCDEFGHIJ, всяка от които е с равна вероятност за срещане от 0.1. На стъпка 1 ще започнем с:

A(0.1)   B(0.1)   C(0.1)   D(0.1)   E(0.1)   F(0.1)   G(0.1)   H(0.1)   I(0.1)   J(0.1)

На стъпка 2 ще изберем два елемента, които имат най-малка вероятност. Понеже всички са с равна вероятност, можем да изберем кои да е 2, т.е. например последните:

                                                                             (0.2)
                                                                          0 /     \ 1
                                                                           /       \
A(0.1)   B(0.1)   C(0.1)   D(0.1)   E(0.1)   F(0.1)   G(0.1)   H(0.1)   I(0.1)   J(0.1)

Сега трябва да изберем нови два върха, които са с най-малка вероятност. Очевидно (0.2) няма да участва. Следващото обединение ще е на G и H, после на E и F, после на C и D и накрая на A и B. Тоест стъпки 3, 4, 5 и 6 ще доведат до:

     (0.2)             (0.2)             (0.2)             (0.2)             (0.2)
  0 /     \ 1       0 /     \ 1       0 /     \ 1       0 /     \ 1       0 /     \ 1
   /       \         /       \         /       \         /       \         /       \
A(0.1)   B(0.1)   C(0.1)   D(0.1)   E(0.1)   F(0.1)   G(0.1)   H(0.1)   I(0.1)   J(0.1)

Вероятно вече се досещате, че следващите две стъпки ще обединят четири от върховете по следния начин:

                            ____(0.4)____                       ____(0.4)____
                         0 /             \ 1                 0 /             \ 1
                          /               \                   /               \
     (0.2)             (0.2)             (0.2)             (0.2)             (0.2)
  0 /     \ 1       0 /     \ 1       0 /     \ 1       0 /     \ 1       0 /     \ 1
   /       \         /       \         /       \         /       \         /       \
A(0.1)   B(0.1)   C(0.1)   D(0.1)   E(0.1)   F(0.1)   G(0.1)   H(0.1)   I(0.1)   J(0.1)

Следващото обединение трябва да е между останалия връх (0.2) и съседния до неко (0.4):

             _______(0.6)_______
          0 /                   \ 1
           /                     \
          /                 ____(0.4)____                       ____(0.4)____
         /               0 /             \ 1                 0 /             \ 1
        /                 /               \                   /               \
     (0.2)             (0.2)             (0.2)             (0.2)             (0.2)
  0 /     \ 1       0 /     \ 1       0 /     \ 1       0 /     \ 1       0 /     \ 1
   /       \         /       \         /       \         /       \         /       \
A(0.1)   B(0.1)   C(0.1)   D(0.1)   E(0.1)   F(0.1)   G(0.1)   H(0.1)   I(0.1)   J(0.1)

Финално съставяме крайното дърво за кодиране:

                         _________________(1.0)__________________
                      0 /                                        \ 1
                       /                                          \
             _______(0.6)_______                                   \
          0 /                   \ 1                                 \
           /                     \                                   \
          /                 ____(0.4)____                       ____(0.4)____
         /               0 /             \ 1                 0 /             \ 1
        /                 /               \                   /               \
     (0.2)             (0.2)             (0.2)             (0.2)             (0.2)
  0 /     \ 1       0 /     \ 1       0 /     \ 1       0 /     \ 1       0 /     \ 1
   /       \         /       \         /       \         /       \         /       \
A(0.1)   B(0.1)   C(0.1)   D(0.1)   E(0.1)   F(0.1)   G(0.1)   H(0.1)   I(0.1)   J(0.1)
Вече можем да построим следната кодираща таблица:

A <-> 000
B <-> 001
C <-> 0100
D <-> 0101
E <-> 0110
F <-> 0111
G <-> 100
H <-> 101
I <-> 110
J <-> 111
Разбира се при реално компресиране ще имаме доста по-голяма азбука (всъщност тя трябва да е такава, че съдържанието на целия файл да може да се опише чрез нея). 
Кодирането на Хъфман се използва при моделите за компресиране deflate (zip, bzip2), JPEG, и др. Трябва да се отбележи специално, 
че при по-къса азбука (нещо, което търсим заради значително по-голямата бързина) и неравномерни вероятности за буквите (получава се често именно при къси азбуки) се получава неефективно разпределение на дължините на кодовете, което води до неоптималност на компресията.
 Проблемът се разрешава с увеличение на дължината на азбуката, но това води до експоненциално забавяне. При компресиращите програми може да видите често, че при създаване на архивен файл има „ниво на компресия“, например при архивиране в ZIP – повишаването му е именно разширяване на азбуката, 
което води и до забавяне на компресирането;

Друго нещо, което не споменахме, е отбелязването на „край на файл“. Нужно е да се измисли специален код, който да дефинира „край на компресирания файл“. Обикновено се прави чрез въвеждането на специална буква в азбуката.


Адаптивно (динамично) кодиране на Хъфман

Допълнително към казаното, кодирането на Хъфман може да е статично или динамично. При статичното кодиране компресиращият алгоритъм първо минава през текста и пресмята вероятностите за срещане на всяка буква, след което строи дървото и записва това дърво като част от компресирания текст. 
При динамичното кодиране дървото не се записва като част от компресирания текст, а се пресъздава (дообогатява и преизчислява) отново и отново с всяка компресирана/декомпресирана поредица. Обикновено в практиката се използва предимно статично компресиране, 
защото рядко спестеното място от съхранение на дървото води до по-голяма компресия (при динамичното компресиране имаме значителна загуба на КПД в началото на текста), но в същото време строенето на тези поредици от бинарни дървета прави динамичното компресиране много по-бавно. 

Аритметично кодиране

Аритметичното кодиране е основата на почти всички по-нови алгоритми за компресиране. Измислено е отдавна, но е било патентовано и това е попречило на по-широкото му разпространение до средата на 90-те. При него на всеки текст, който искаме да компресираме, се съпоставя едно единствено число с плаваща запетая.
 Разбира се не говорим за стандартен тип float или double, а за много голямо число (заемащо много повече битове). Процесът на компресиране се прави постъпково. С всяка нова буква от съобщението се добавят допълнителни битове към крайното число. Както и при кодирането на Хъфман,
 тук също зависим от модел на компресирането, т.е. в частност трябва предварително да са зададени вероятностите за това дадена буква да се срещне в текста.

Нека приемем, че за всяка буква x имаме вероятност за срещане P(x). Ясно е, че сумата от вероятностите за всички букви, които се срещат в текста, който ще кодираме, трябва да е равна на 1. Следващото нещо, което ще направим е да подредим тези низове в някакъв определен ред, например за удобство ще вземем лексикографски, 
но не е проблем да е какъвто и да е друг (например по реда на срещане на буквите), стига компресиращия и декомпресиращия алгоритъм да използват един и същ ред.

Нека например имаме съобщение DCAB, което е изградено от букви D, C, A и B. Очевидно е, че техните вероятности вероятности за срещане в текста са, т.е. P(D)=0.25, P(C)=0.25, P(A)=0.25 и P(B)=0.25. Лексикографската подребда на азбуката ще бъде {A,B,C,D}. Така ще разграфим интервала [0,1) (търсеното число,
 което ще представлява компресирания текст, ще бъде в този инвервал) в тези четири точки:

    A          B          C          D
0-------0.25-------0.50-------0.75-------1.00
От тук нататък кодирането на поредни низове от съобщението се прави, както написахме по-горе, постъпково. Ако в самото начало интервала е бил [0,1], то при прочитането на буква D на първа стъпка, интервала се скъсява до [0.75, 1], в смисъл, че крайното число (компресирания текст във вид на число с плаваща запетая) ще бъде в този интервал!
 Преди постъпването на следващия низ, разделяме новия интервал пропорционално по същият начин, както го направихме първоначално:

       A             B           C           D
0.75-------0.8125-------0.875-------0.9375-------1.00
На следващата стъпка постъпва буква C. Тоест новият интервал става [0.875,0.9375):

       A               B             C              D
0.875-------0.890665-------0.90625-------0.921875-------0.9375
Следващата буква е A, т.е. интервалът се скъсява до [0.875,0.890665):

       A                 B               C                D
0.875-------0.87891625-------0.8828325-------0.88674875-------0.890665
Финално постъпва буква B, т.е. крайния интервал е [0.87891625,0.8828325). Компресираният текст ще бъде число с праваща запетая в този интервал.

За да достигнем до по-формална дефиниция, ще дефинираме P(<x) да е сумата от вероятностите на всички букви, които са лексикографски по-малки от x. От примера P(<A)=0, P(<B)=0.25, P(<C)=0.50 и P(<D)=0.75. Нека дефинираме и P(≤x) = P(<x)+P(x). От примера P(≤A)=0.25, P(≤B)=0.50, P(≤C)=0.75 и P(≤D)=1.00.

Всяко число с плаваща запетая, което попада в интервала от примера, би било достатъчно за да определи еднозначно входящото съобщение по дадения модел, т.е. би могло да го декомпресира. Ние обаче търсим оптималност – максимална компресия, – т.е. търсим такова число с плаваща запетая от получения интервал, че да заеме минимално количество битове. Тоест можем да кажем формално, 
че аритметичното кодиране на буква x е най-късото бинарно число y, такова че P(<x) ≤ y < P(≤x). От тук и аритметичното кодиране на текста ще бъде натрупване на кодиранията на всяка буква. Първата ще определи грубо границите на интервала, втората ще прецизира малко, третата още малко, и т.н.

Намирането на най-късото бинарно число в случая е лесно като се сетим, че просто трябва да намерим сума от рационални числа от вида 1/x, където x е степен на двойката. Причината да търсим степени на двойката в знаменателя е, че именно те представляват най-късата бинарна поредица. Например в интервала [0,1,0.3) най-късата бинарна поредица ще е числото 0.25, което всъщност е 1/4. Ето една програма на Java, която намира числото, което представлява най-къса бинарна поредица в интервал [0.1), но с тип данни double, т.е. доста слаба прецизност спрямо това, което се търси в задачата:

public class ShortestBinaryInInterval {
    public static void main(String[] args) throws Exception{
        double test = shortest(0.3,0.5);
        System.out.println("Double: "+test);
    }

    static double nextHigherInteger(double current) {
        double next = Math.ceil(current);
        if(Double.compare(current, next) == 0) {
            next++;
        }
        return current;
    }

    static double shortest(double low, double high) throws Exception{
        double result = nextHigherInteger(high);
        double intervalFraction = 1;
        while (Double.compare(intervalFraction, 0)!=0) {
            intervalFraction /= 2;
            if (result <= low) {
                result += intervalFraction;
            } else if (result >= high) {
                result -= intervalFraction;
            } else {
                return result;
            }
        }
        throw new Exception("Интервалът е прекалено къс за тип double");
    }
}
Проследете кода и ще разберете основната идея – започваме да наситняваме интервал и съответно добавяме или изваждаме 1/2, 1/4, 1/8 и т.н.,
 докато в един момент ни удовлетвори. 
Ако интервалът е прекалено къс, ние няма да можем да влезем с него с тип double, поради което хвърляме изключение.
 При реално действащ алгоритъм, ще бъде използван съответен тип данни с увеличаваща се точност, за да може винаги да се достигне до краен резултат.
Тук обаче има една важна уговорка – ако компресираме кратки текстове, статичното кодиране е по-неефективно, защото не си заслужава записването на информацията за дървото.